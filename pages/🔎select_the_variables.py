import streamlit as st
import numpy as np
import pandas as pd
import arfs.feature_selection as arfsfs
from sklearn.pipeline import Pipeline
import arfs.feature_selection.allrelevant as arfsgroot
from arfs.feature_selection import (
    MinRedundancyMaxRelevance,
    GrootCV,
    MissingValueThreshold,
    UniqueValuesThreshold,
    CollinearityThreshold,
    make_fs_summary,
)
from arfs.utils import LightForestClassifier, LightForestRegressor
from arfs.benchmark import highlight_tick, compare_varimp, sklearn_pimp_bench
from lightgbm import LGBMRegressor, LGBMClassifier
import matplotlib.pyplot as plt
from arfs.preprocessing import OrdinalEncoderPandas



if __name__ == '__main__':
    st.title("ğŸ”å˜é‡ç­›é€‰")
    model_type=st.radio('æ¨¡å‹ç±»åˆ«é€‰æ‹©', ('å›å½’', 'åˆ†ç±»'),horizontal=True)

    upload_file=st.file_uploader('ä¸Šä¼ æ•°æ®' , type=['csv'], key='upload_file')
    if upload_file is not None:
        data = pd.read_csv(upload_file)
    else:
        if model_type=='å›å½’':
            data = pd.read_csv('Housing_Price_Data.csv')
        else:
            data = pd.read_csv('SAHeart.csv')
        
    X_drop=st.multiselect('æ’é™¤çš„æŒ‡æ ‡ï¼ˆæ¯”å¦‚ç¼–å·ç­‰ï¼‰', data.columns)
    outcome=st.selectbox('é€‰æ‹©ç»“å±€æŒ‡æ ‡ï¼ˆå…¶å®ƒæŒ‡æ ‡ä½œä¸ºé¢„æµ‹æŒ‡æ ‡ï¼‰', data.columns)
    
    data=data.drop(X_drop, axis=1)
    
    X=data.drop([outcome],axis=1)
    #basic selected
    basic_fs_pipeline = Pipeline(
    [
        ("missing", arfsfs.MissingValueThreshold(threshold=0.05)),
        ("unique", arfsfs.UniqueValuesThreshold(threshold=1)),
        ("cardinality", arfsfs.CardinalityThreshold(threshold=10)),
        ("collinearity", arfsfs.CollinearityThreshold(threshold=0.75)),
        ("encoder", OrdinalEncoderPandas())
    ]
)

    X=basic_fs_pipeline.fit_transform(X, y=None)
    y=data[outcome]
    
  
    if 'X' not in st.session_state:
        st.session_state.X = X
        st.session_state.y = y
    else:
        st.session_state.X = X
        st.session_state.y = y
    # æ•°æ®ç­›é€‰
    
    '***'
    with st.container():
        if model_type=='å›å½’':
            model_lg = LGBMRegressor(random_state=42, verbose=-1)
        else:
            model_lg = LGBMClassifier(random_state=42, verbose=-1)
            
        st.header(' Leshy ç®—æ³•ï¼ˆæ¥è‡ªpython-arfsåŒ…ï¼‰')
        # importance=st.radio('ç®—æ³•ä¸­é‡è¦æ€§å‚æ•°', ('naive'),horizontal=True)
        feat_selector = arfsgroot.Leshy(
            model_lg, n_estimators=20, verbose=1, max_iter=10, random_state=42, importance='naive'
        )
        feat_selector.fit(X, y, sample_weight=None)
        
        selected_features = feat_selector.get_feature_names_out()
        if 'selected_features' not in st.session_state:
            st.session_state.selected_features = selected_features
        else:
            st.session_state.selected_features = selected_features
        
        
        fig = feat_selector.plot_importance(n_feat_per_inch=5)
        fig.set_size_inches(10, 5)
        # highlight synthetic random variable
        fig = highlight_tick(figure=fig, str_match="random")
        fig = highlight_tick(figure=fig, str_match="genuine", color="green")

        dic_ft_select = pd.DataFrame({'name':X.columns, 'rank':feat_selector.ranking_,'selected':feat_selector.support_})
        dic_ft_select=dic_ft_select.sort_values('rank',ascending=True)
    

        st.write(fig)
        st.write(dic_ft_select.T)
        st.write('è¯´æ˜ï¼šå›¾ä¸­è“è‰²æ¡†è¡¨ç¤ºè¢«é€‰ä¸­çš„ç‰¹å¾,å¯¹åº”è¡¨æ ¼ä¸­rankä¸º1çš„å˜é‡ï¼Œè€Œçº¢è‰²æ¡†è¡¨ç¤ºè¢«æ’é™¤çš„ç‰¹å¾ã€‚åç»­çš„SHAPåˆ†æèšç„¦åœ¨è¢«é€‰ä¸­çš„ç‰¹å¾ä¸Šè¿›è¡Œï¼Œå› è€Œå¢åŠ äº†åˆ†æçš„é€Ÿåº¦å’Œæ•ˆç‡ã€‚')
    '***'
    with st.container():
        st.header('æ•°æ®å±•ç¤ºï¼š')
        st.write(st.session_state.X)